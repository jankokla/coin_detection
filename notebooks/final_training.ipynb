{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Final Training"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "397655b8458c38cc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9902570e863ba0d"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T09:07:44.077632Z",
     "start_time": "2024-05-21T09:07:44.059128Z"
    }
   },
   "id": "a31e34bbb14feb2"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-23T14:04:32.841510Z",
     "start_time": "2024-05-23T14:04:26.230404Z"
    }
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "dlopen(/Users/jan.kokla/miniconda3/envs/iapr_project/lib/python3.9/site-packages/torchaudio/_torchaudio.so, 0x0006): Symbol not found: __ZNK3c104Type14isSubtypeOfExtERKNSt3__110shared_ptrIS0_EEPNS1_13basic_ostreamIcNS1_11char_traitsIcEEEE\n  Referenced from: <D1FEA5E2-D31D-3375-AD47-CD1FABF9F7C5> /Users/jan.kokla/miniconda3/envs/iapr_project/lib/python3.9/site-packages/torchaudio/_torchaudio.so\n  Expected in:     <12FB406D-F8AC-3782-A1E8-ADE5A43768BA> /Users/jan.kokla/miniconda3/envs/iapr_project/lib/python3.9/site-packages/torch/lib/libtorch_cpu.dylib",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 5\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01malbumentations\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mA\u001B[39;00m\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscripts\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m CoinClassifier\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscripts\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtraining\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m train_model, save_trainable_params\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscripts\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m split_data, get_images_from_coco, ClassificationDataset, setup_seed\n",
      "File \u001B[0;32m~/Documents/EPFL/coin_detection/scripts/models.py:10\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msegmentation_models_pytorch\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01msmp\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m nn\n\u001B[0;32m---> 10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscripts\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtraining\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m load_params\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mCoinClassifier\u001B[39;00m(nn\u001B[38;5;241m.\u001B[39mModule):\n\u001B[1;32m     14\u001B[0m     task \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclassification\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m~/Documents/EPFL/coin_detection/scripts/training.py:15\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m functional \u001B[38;5;28;01mas\u001B[39;00m F\n\u001B[1;32m     14\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m CrossEntropyLoss\n\u001B[0;32m---> 15\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorcheval\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m multiclass_f1_score \u001B[38;5;28;01mas\u001B[39;00m f1_eval\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtqdm\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m tqdm\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mMetricMonitor\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniconda3/envs/iapr_project/lib/python3.9/site-packages/torcheval/metrics/__init__.py:9\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorcheval\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m functional\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorcheval\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01maggregation\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m AUC, Cat, Max, Mean, Min, Sum, Throughput\n\u001B[0;32m----> 9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorcheval\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01maudio\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FrechetAudioDistance\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorcheval\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mclassification\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     11\u001B[0m     BinaryAccuracy,\n\u001B[1;32m     12\u001B[0m     BinaryAUPRC,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     41\u001B[0m     TopKMultilabelAccuracy,\n\u001B[1;32m     42\u001B[0m )\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorcheval\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mimage\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FrechetInceptionDistance, PeakSignalNoiseRatio\n",
      "File \u001B[0;32m~/miniconda3/envs/iapr_project/lib/python3.9/site-packages/torcheval/metrics/audio/__init__.py:7\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Copyright (c) Meta Platforms, Inc. and affiliates.\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;66;03m# All rights reserved.\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# This source code is licensed under the BSD-style license found in the\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# LICENSE file in the root directory of this source tree.\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorcheval\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmetrics\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01maudio\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfad\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FrechetAudioDistance\n\u001B[1;32m     10\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFrechetAudioDistance\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/miniconda3/envs/iapr_project/lib/python3.9/site-packages/torcheval/metrics/audio/fad.py:13\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 13\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchaudio\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfunctional\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m frechet_distance\n\u001B[1;32m     15\u001B[0m     _TORCHAUDIO_AVAILABLE \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n",
      "File \u001B[0;32m~/miniconda3/envs/iapr_project/lib/python3.9/site-packages/torchaudio/__init__.py:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m extension  \u001B[38;5;66;03m# noqa: F401\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchaudio\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_internal\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m module_utils \u001B[38;5;28;01mas\u001B[39;00m _mod_utils  \u001B[38;5;66;03m# noqa: F401\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorchaudio\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m      4\u001B[0m     compliance,\n\u001B[1;32m      5\u001B[0m     datasets,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     10\u001B[0m     transforms,\n\u001B[1;32m     11\u001B[0m )\n",
      "File \u001B[0;32m~/miniconda3/envs/iapr_project/lib/python3.9/site-packages/torchaudio/extension/__init__.py:5\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mextension\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m      2\u001B[0m     _init_extension,\n\u001B[1;32m      3\u001B[0m )\n\u001B[0;32m----> 5\u001B[0m \u001B[43m_init_extension\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mdel\u001B[39;00m _init_extension\n",
      "File \u001B[0;32m~/miniconda3/envs/iapr_project/lib/python3.9/site-packages/torchaudio/extension/extension.py:11\u001B[0m, in \u001B[0;36m_init_extension\u001B[0;34m()\u001B[0m\n\u001B[1;32m      9\u001B[0m ext \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtorchaudio._torchaudio\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _mod_utils\u001B[38;5;241m.\u001B[39mis_module_available(ext):\n\u001B[0;32m---> 11\u001B[0m     \u001B[43m_init_script_module\u001B[49m\u001B[43m(\u001B[49m\u001B[43mext\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     13\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtorchaudio C++ extension is not available.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/iapr_project/lib/python3.9/site-packages/torchaudio/extension/extension.py:18\u001B[0m, in \u001B[0;36m_init_script_module\u001B[0;34m(module)\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_init_script_module\u001B[39m(module):\n\u001B[1;32m     17\u001B[0m     path \u001B[38;5;241m=\u001B[39m importlib\u001B[38;5;241m.\u001B[39mutil\u001B[38;5;241m.\u001B[39mfind_spec(module)\u001B[38;5;241m.\u001B[39morigin\n\u001B[0;32m---> 18\u001B[0m     \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclasses\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_library\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m     torch\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39mload_library(path)\n",
      "File \u001B[0;32m~/miniconda3/envs/iapr_project/lib/python3.9/site-packages/torch/_classes.py:51\u001B[0m, in \u001B[0;36m_Classes.load_library\u001B[0;34m(self, path)\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_library\u001B[39m(\u001B[38;5;28mself\u001B[39m, path):\n\u001B[1;32m     34\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     35\u001B[0m \u001B[38;5;124;03m    Loads a shared library from the given path into the current process.\u001B[39;00m\n\u001B[1;32m     36\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[38;5;124;03m        path (str): A path to a shared library to load.\u001B[39;00m\n\u001B[1;32m     50\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 51\u001B[0m     \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_library\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/iapr_project/lib/python3.9/site-packages/torch/_ops.py:852\u001B[0m, in \u001B[0;36m_Ops.load_library\u001B[0;34m(self, path)\u001B[0m\n\u001B[1;32m    847\u001B[0m path \u001B[38;5;241m=\u001B[39m _utils_internal\u001B[38;5;241m.\u001B[39mresolve_library_path(path)\n\u001B[1;32m    848\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m dl_open_guard():\n\u001B[1;32m    849\u001B[0m     \u001B[38;5;66;03m# Import the shared library into the process, thus running its\u001B[39;00m\n\u001B[1;32m    850\u001B[0m     \u001B[38;5;66;03m# static (global) initialization code in order to register custom\u001B[39;00m\n\u001B[1;32m    851\u001B[0m     \u001B[38;5;66;03m# operators with the JIT.\u001B[39;00m\n\u001B[0;32m--> 852\u001B[0m     \u001B[43mctypes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mCDLL\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    853\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloaded_libraries\u001B[38;5;241m.\u001B[39madd(path)\n",
      "File \u001B[0;32m~/miniconda3/envs/iapr_project/lib/python3.9/ctypes/__init__.py:382\u001B[0m, in \u001B[0;36mCDLL.__init__\u001B[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001B[0m\n\u001B[1;32m    379\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_FuncPtr \u001B[38;5;241m=\u001B[39m _FuncPtr\n\u001B[1;32m    381\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m handle \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 382\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle \u001B[38;5;241m=\u001B[39m \u001B[43m_dlopen\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    383\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    384\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_handle \u001B[38;5;241m=\u001B[39m handle\n",
      "\u001B[0;31mOSError\u001B[0m: dlopen(/Users/jan.kokla/miniconda3/envs/iapr_project/lib/python3.9/site-packages/torchaudio/_torchaudio.so, 0x0006): Symbol not found: __ZNK3c104Type14isSubtypeOfExtERKNSt3__110shared_ptrIS0_EEPNS1_13basic_ostreamIcNS1_11char_traitsIcEEEE\n  Referenced from: <D1FEA5E2-D31D-3375-AD47-CD1FABF9F7C5> /Users/jan.kokla/miniconda3/envs/iapr_project/lib/python3.9/site-packages/torchaudio/_torchaudio.so\n  Expected in:     <12FB406D-F8AC-3782-A1E8-ADE5A43768BA> /Users/jan.kokla/miniconda3/envs/iapr_project/lib/python3.9/site-packages/torch/lib/libtorch_cpu.dylib"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import albumentations as A\n",
    "\n",
    "from scripts.models import CoinClassifier\n",
    "from scripts.training import train_model, save_trainable_params\n",
    "from scripts.utils import split_data, get_images_from_coco, ClassificationDataset, setup_seed\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "from pathlib import Path\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameters and Config"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96f2763e18d70013"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "setup_seed(13)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T09:08:09.653626Z",
     "start_time": "2024-05-21T09:08:09.613014Z"
    }
   },
   "id": "4b9cf42ef3f66cf2"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "ROOT = Path(os.path.abspath('')).parent\n",
    "\n",
    "# let's specify paths to training images and masks\n",
    "images_path = \"../data/train\"\n",
    "coins_path = \"../data/classification\"\n",
    "labels_path = \"../data/classification/labels.json\"\n",
    "\n",
    "annotation_path = \"../data/annotations.json\"\n",
    "cls_path = \"../data/classification\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T09:14:29.737712Z",
     "start_time": "2024-05-21T09:14:29.679824Z"
    }
   },
   "id": "482af80288f4ff8e"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# training hyperparameters\n",
    "batch_size = 8"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T09:08:10.180764Z",
     "start_time": "2024-05-21T09:08:10.144710Z"
    }
   },
   "id": "162acd40428ef0df"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Transformations\n",
    "\n",
    "We first define data augmentations for more robust model. Since our backbones are pretrained on Imagenet, we apply dataset specific normalization to the transformations."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abeab7013d2e70cf"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already there, good to go!\n"
     ]
    }
   ],
   "source": [
    "# cut coins from images if necessary and save them as separate images\n",
    "get_images_from_coco(images_path, annotation_path, cls_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T09:08:10.797544Z",
     "start_time": "2024-05-21T09:08:10.754033Z"
    }
   },
   "id": "cfffe5b404c0242c"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# imagenet specific normalization (was applied also during backbone training)\n",
    "normalization_kwargs = {\n",
    "    'mean': (0.485, 0.456, 0.406), \n",
    "    'std': (0.229, 0.224, 0.225), \n",
    "    'always_apply': True\n",
    "}\n",
    "\n",
    "# define data augmentation for train and validation\n",
    "train_tf = A.Compose([\n",
    "    A.Resize(width=224, height=224, always_apply=True),\n",
    "    A.RandomRotate90(p=0.9),\n",
    "    A.RandomBrightnessContrast(p=0.5),\n",
    "    A.Blur(blur_limit=3),\n",
    "    A.OpticalDistortion(),\n",
    "    A.Normalize(**normalization_kwargs)\n",
    "])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T09:16:01.055269Z",
     "start_time": "2024-05-21T09:16:00.980716Z"
    }
   },
   "id": "df9d3276380a5ede"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modelling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd40540760177806"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predicting Currency\n",
    "\n",
    "We first build a classifier that will separate between EUR and CHF."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36e7b2ddc6098902"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Datasets and DataLoaders"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65dbd6077fadba13"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "# split the image paths into train and validation\n",
    "images_train, images_val, labels_train, labels_val = split_data(\n",
    "    coins_path, 0, \"classification\", labels_path, \"ccy\"\n",
    ")\n",
    "\n",
    "# get train and val dataset instances\n",
    "train_ds = ClassificationDataset(\n",
    "    image_paths=images_train,\n",
    "    labels=labels_train,\n",
    "    transform=train_tf,\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T09:16:03.778786Z",
     "start_time": "2024-05-21T09:16:03.735079Z"
    }
   },
   "id": "b3f1e6eee882d4aa"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Modelling\n",
    "\n",
    "We use `Segmentation Models Pytorch` for model generation, then we define training arguments and train the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eec27faf679b87e0"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "model = CoinClassifier(num_classes=2, coin_type=\"ccy\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T09:16:06.647065Z",
     "start_time": "2024-05-21T09:16:05.573222Z"
    }
   },
   "id": "9be69d7f2152f2c3"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.model.head.parameters(), lr=0.0005)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=5, eta_min=1e-6)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T09:16:06.686379Z",
     "start_time": "2024-05-21T09:16:06.649664Z"
    }
   },
   "id": "3924c5ec9264dbcc"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   1. Train.      Loss: 0.554 | f1: 0.704: 100%|██████████| 42/42 [00:05<00:00,  7.37it/s]\n",
      "Epoch:   2. Train.      Loss: 0.268 | f1: 0.964: 100%|██████████| 42/42 [00:05<00:00,  7.45it/s]\n",
      "Epoch:   3. Train.      Loss: 0.174 | f1: 0.988: 100%|██████████| 42/42 [00:05<00:00,  7.67it/s]\n",
      "Epoch:   4. Train.      Loss: 0.137 | f1: 0.970: 100%|██████████| 42/42 [00:05<00:00,  7.68it/s]\n",
      "Epoch:   5. Train.      Loss: 0.104 | f1: 0.988: 100%|██████████| 42/42 [00:05<00:00,  7.37it/s]\n",
      "Epoch:   6. Train.      Loss: 0.090 | f1: 0.991: 100%|██████████| 42/42 [00:05<00:00,  7.39it/s]\n",
      "Epoch:   7. Train.      Loss: 0.085 | f1: 0.991: 100%|██████████| 42/42 [00:05<00:00,  7.22it/s]\n",
      "Epoch:   8. Train.      Loss: 0.071 | f1: 0.991: 100%|██████████| 42/42 [00:06<00:00,  6.98it/s]\n",
      "Epoch:   9. Train.      Loss: 0.066 | f1: 0.994: 100%|██████████| 42/42 [00:06<00:00,  6.43it/s]\n",
      "Epoch:  10. Train.      Loss: 0.062 | f1: 0.991: 100%|██████████| 42/42 [00:06<00:00,  6.49it/s]\n",
      "Epoch:  11. Train.      Loss: 0.055 | f1: 0.994: 100%|██████████| 42/42 [00:06<00:00,  6.64it/s]\n",
      "Epoch:  12. Train.      Loss: 0.058 | f1: 0.994: 100%|██████████| 42/42 [00:06<00:00,  6.57it/s]\n",
      "Epoch:  13. Train.      Loss: 0.047 | f1: 0.997: 100%|██████████| 42/42 [00:06<00:00,  6.13it/s]\n",
      "Epoch:  14. Train.      Loss: 0.052 | f1: 0.997: 100%|██████████| 42/42 [00:07<00:00,  5.87it/s]\n",
      "Epoch:  15. Train.      Loss: 0.049 | f1: 0.997: 100%|██████████| 42/42 [00:06<00:00,  6.20it/s]\n",
      "Epoch:  16. Train.      Loss: 0.050 | f1: 0.994: 100%|██████████| 42/42 [00:07<00:00,  5.82it/s]\n",
      "Epoch:  17. Train.      Loss: 0.041 | f1: 0.994: 100%|██████████| 42/42 [00:07<00:00,  5.96it/s]\n",
      "Epoch:  18. Train.      Loss: 0.050 | f1: 0.991: 100%|██████████| 42/42 [00:07<00:00,  5.94it/s]\n",
      "Epoch:  19. Train.      Loss: 0.045 | f1: 0.997: 100%|██████████| 42/42 [00:06<00:00,  6.01it/s]\n",
      "Epoch:  20. Train.      Loss: 0.038 | f1: 0.997: 100%|██████████| 42/42 [00:06<00:00,  6.02it/s]\n",
      "Epoch:  21. Train.      Loss: 0.039 | f1: 0.997: 100%|██████████| 42/42 [00:06<00:00,  6.02it/s]\n",
      "Epoch:  22. Train.      Loss: 0.034 | f1: 0.997: 100%|██████████| 42/42 [00:07<00:00,  5.98it/s]\n",
      "Epoch:  23. Train.      Loss: 0.032 | f1: 0.997: 100%|██████████| 42/42 [00:06<00:00,  6.13it/s]\n",
      "Epoch:  24. Train.      Loss: 0.035 | f1: 0.997: 100%|██████████| 42/42 [00:07<00:00,  6.00it/s]\n",
      "Epoch:  25. Train.      Loss: 0.036 | f1: 0.997: 100%|██████████| 42/42 [00:07<00:00,  5.92it/s]\n",
      "Epoch:  26. Train.      Loss: 0.036 | f1: 0.994: 100%|██████████| 42/42 [00:07<00:00,  5.86it/s]\n",
      "Epoch:  27. Train.      Loss: 0.030 | f1: 0.997: 100%|██████████| 42/42 [00:07<00:00,  5.92it/s]\n",
      "Epoch:  28. Train.      Loss: 0.047 | f1: 0.994: 100%|██████████| 42/42 [00:07<00:00,  5.82it/s]\n",
      "Epoch:  29. Train.      Loss: 0.036 | f1: 0.997: 100%|██████████| 42/42 [00:07<00:00,  5.71it/s]\n",
      "Epoch:  30. Train.      Loss: 0.033 | f1: 0.997: 100%|██████████| 42/42 [00:07<00:00,  5.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "_ = train_model(\n",
    "    model,\n",
    "    (train_loader, None),\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    num_epochs=30\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T09:19:25.685920Z",
     "start_time": "2024-05-21T09:16:07.099765Z"
    }
   },
   "id": "974b5b85673d145e"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "filepath = f'{ROOT}/models/{model.task}_{model.coin_type}.pt'\n",
    "save_trainable_params(model, filepath)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T09:19:25.769224Z",
     "start_time": "2024-05-21T09:19:25.673907Z"
    }
   },
   "id": "4dc82712177ea8f3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predicting EUR\n",
    "\n",
    "Now we can build a classifier to distinguish between EUR coin types."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "adbfd3e2fc3cf4d0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Datasets and DataLoaders"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e97693192c514b3a"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'split_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# split the image paths into train and validation\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m images_train, _, labels_train, _ \u001B[38;5;241m=\u001B[39m \u001B[43msplit_data\u001B[49m(\n\u001B[1;32m      3\u001B[0m     coins_path, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclassification\u001B[39m\u001B[38;5;124m\"\u001B[39m, labels_path, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124meur\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      4\u001B[0m )\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# get train and val dataset instances\u001B[39;00m\n\u001B[1;32m      7\u001B[0m train_ds \u001B[38;5;241m=\u001B[39m ClassificationDataset(\n\u001B[1;32m      8\u001B[0m     image_paths\u001B[38;5;241m=\u001B[39mimages_train,\n\u001B[1;32m      9\u001B[0m     labels\u001B[38;5;241m=\u001B[39mlabels_train,\n\u001B[1;32m     10\u001B[0m     transform\u001B[38;5;241m=\u001B[39mtrain_tf\n\u001B[1;32m     11\u001B[0m )\n",
      "\u001B[0;31mNameError\u001B[0m: name 'split_data' is not defined"
     ]
    }
   ],
   "source": [
    "# split the image paths into train and validation\n",
    "images_train, _, labels_train, _ = split_data(\n",
    "    coins_path, 0, \"classification\", labels_path, \"eur\"\n",
    ")\n",
    "\n",
    "# get train and val dataset instances\n",
    "train_ds = ClassificationDataset(\n",
    "    image_paths=images_train,\n",
    "    labels=labels_train,\n",
    "    transform=train_tf\n",
    ")\n",
    "\n",
    "# create dataloaders\n",
    "train_loader = DataLoader(train_ds, batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T14:04:20.717167Z",
     "start_time": "2024-05-23T14:04:20.487896Z"
    }
   },
   "id": "f8d499ed85d5a84b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Modelling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "39beaedc84ee5001"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = CoinClassifier(num_classes=8, coin_type=\"eur\", freeze=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T14:04:20.721274Z",
     "start_time": "2024-05-23T14:04:20.721181Z"
    }
   },
   "id": "2d6789f1a7abeead"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m criterion \u001B[38;5;241m=\u001B[39m \u001B[43mnn\u001B[49m\u001B[38;5;241m.\u001B[39mCrossEntropyLoss()\n\u001B[1;32m      2\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.00003\u001B[39m)\n\u001B[1;32m      3\u001B[0m scheduler \u001B[38;5;241m=\u001B[39m CosineAnnealingLR(optimizer, T_max\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, eta_min\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-6\u001B[39m)\n",
      "\u001B[0;31mNameError\u001B[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.00003)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=5, eta_min=1e-6)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-23T14:04:21.250348Z",
     "start_time": "2024-05-23T14:04:21.224422Z"
    }
   },
   "id": "39050e45f30c3bb5"
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   1. Train.      Loss: 1.934 | f1: 0.280: 100%|██████████| 25/25 [00:12<00:00,  2.08it/s]\n",
      "Epoch:   2. Train.      Loss: 1.175 | f1: 0.550: 100%|██████████| 25/25 [00:11<00:00,  2.12it/s]\n",
      "Epoch:   3. Train.      Loss: 0.675 | f1: 0.825: 100%|██████████| 25/25 [00:12<00:00,  2.00it/s]\n",
      "Epoch:   4. Train.      Loss: 0.458 | f1: 0.910: 100%|██████████| 25/25 [00:13<00:00,  1.84it/s]\n",
      "Epoch:   5. Train.      Loss: 0.279 | f1: 0.960: 100%|██████████| 25/25 [00:14<00:00,  1.71it/s]\n",
      "Epoch:   6. Train.      Loss: 0.181 | f1: 0.980: 100%|██████████| 25/25 [00:15<00:00,  1.66it/s]\n",
      "Epoch:   7. Train.      Loss: 0.133 | f1: 0.980: 100%|██████████| 25/25 [00:15<00:00,  1.63it/s]\n",
      "Epoch:   8. Train.      Loss: 0.111 | f1: 0.980: 100%|██████████| 25/25 [00:14<00:00,  1.70it/s]\n",
      "Epoch:   9. Train.      Loss: 0.077 | f1: 0.990: 100%|██████████| 25/25 [00:14<00:00,  1.76it/s]\n",
      "Epoch:  10. Train.      Loss: 0.082 | f1: 0.980: 100%|██████████| 25/25 [00:14<00:00,  1.76it/s]\n",
      "Epoch:  11. Train.      Loss: 0.051 | f1: 0.995: 100%|██████████| 25/25 [00:14<00:00,  1.68it/s]\n",
      "Epoch:  12. Train.      Loss: 0.052 | f1: 0.990: 100%|██████████| 25/25 [00:14<00:00,  1.71it/s]\n",
      "Epoch:  13. Train.      Loss: 0.048 | f1: 0.990: 100%|██████████| 25/25 [00:14<00:00,  1.73it/s]\n",
      "Epoch:  14. Train.      Loss: 0.019 | f1: 1.000: 100%|██████████| 25/25 [00:14<00:00,  1.76it/s]\n",
      "Epoch:  15. Train.      Loss: 0.015 | f1: 1.000: 100%|██████████| 25/25 [00:14<00:00,  1.77it/s]\n",
      "Epoch:  16. Train.      Loss: 0.013 | f1: 1.000: 100%|██████████| 25/25 [00:14<00:00,  1.77it/s]\n",
      "Epoch:  17. Train.      Loss: 0.012 | f1: 1.000: 100%|██████████| 25/25 [00:14<00:00,  1.76it/s]\n",
      "Epoch:  18. Train.      Loss: 0.009 | f1: 1.000: 100%|██████████| 25/25 [00:14<00:00,  1.76it/s]\n",
      "Epoch:  19. Train.      Loss: 0.009 | f1: 1.000: 100%|██████████| 25/25 [00:14<00:00,  1.77it/s]\n",
      "Epoch:  20. Train.      Loss: 0.007 | f1: 1.000: 100%|██████████| 25/25 [00:14<00:00,  1.77it/s]\n",
      "Epoch:  21. Train.      Loss: 0.007 | f1: 1.000: 100%|██████████| 25/25 [00:14<00:00,  1.74it/s]\n",
      "Epoch:  22. Train.      Loss: 0.006 | f1: 1.000: 100%|██████████| 25/25 [00:14<00:00,  1.74it/s]\n",
      "Epoch:  23. Train.      Loss: 0.006 | f1: 1.000: 100%|██████████| 25/25 [00:13<00:00,  1.89it/s]\n",
      "Epoch:  24. Train.      Loss: 0.006 | f1: 1.000: 100%|██████████| 25/25 [00:12<00:00,  1.93it/s]\n",
      "Epoch:  25. Train.      Loss: 0.005 | f1: 1.000: 100%|██████████| 25/25 [00:13<00:00,  1.86it/s]\n",
      "Epoch:  26. Train.      Loss: 0.004 | f1: 1.000: 100%|██████████| 25/25 [00:12<00:00,  1.95it/s]\n"
     ]
    }
   ],
   "source": [
    "_ = train_model(\n",
    "    model,\n",
    "    (train_loader, None),\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    num_epochs=26\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T09:30:13.327802Z",
     "start_time": "2024-05-21T09:24:10.734698Z"
    }
   },
   "id": "607e078daf0966a5"
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "filepath = f'{ROOT}/models/{model.task}_{model.coin_type}.pt'\n",
    "save_trainable_params(model, filepath)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T09:32:09.032788Z",
     "start_time": "2024-05-21T09:32:08.773071Z"
    }
   },
   "id": "10e105632a682ce0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predicting CHF heads or tails"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92754d76e844bd99"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Datasets and DataLoaders"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e55e54a10c8f71a8"
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# split the image paths into train and validation\n",
    "labels_path = \"../data/classification/heads_tails.json\"\n",
    "images_train, _, labels_train, _ = split_data(\n",
    "    coins_path, 0, \"classification\", labels_path, \"heads-tails\"\n",
    ")\n",
    "\n",
    "# get train and val dataset instances\n",
    "train_ds = ClassificationDataset(\n",
    "    image_paths=images_train,\n",
    "    labels=labels_train,\n",
    "    transform=train_tf,\n",
    ")\n",
    "\n",
    "# create dataloaders\n",
    "train_loader = DataLoader(train_ds, batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T09:32:33.383646Z",
     "start_time": "2024-05-21T09:32:33.313415Z"
    }
   },
   "id": "ee1cf692800c3018"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Modelling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1882a6858089443a"
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "model = CoinClassifier(num_classes=2, coin_type=\"heads-tails\", freeze=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T09:32:36.753920Z",
     "start_time": "2024-05-21T09:32:35.678101Z"
    }
   },
   "id": "c77251c5abf32dcc"
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.model.parameters(), lr=0.00005)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T09:32:37.285140Z",
     "start_time": "2024-05-21T09:32:37.244759Z"
    }
   },
   "id": "320a6856cf3e52af"
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   1. Train.      Loss: 0.556 | f1: 0.763: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n",
      "Epoch:   2. Train.      Loss: 0.110 | f1: 0.978: 100%|██████████| 17/17 [00:05<00:00,  2.84it/s]\n",
      "Epoch:   3. Train.      Loss: 0.041 | f1: 0.985: 100%|██████████| 17/17 [00:06<00:00,  2.81it/s]\n",
      "Epoch:   4. Train.      Loss: 0.025 | f1: 0.993: 100%|██████████| 17/17 [00:06<00:00,  2.79it/s]\n",
      "Epoch:   5. Train.      Loss: 0.010 | f1: 1.000: 100%|██████████| 17/17 [00:05<00:00,  2.97it/s]\n",
      "Epoch:   6. Train.      Loss: 0.007 | f1: 1.000: 100%|██████████| 17/17 [00:06<00:00,  2.49it/s]\n",
      "Epoch:   7. Train.      Loss: 0.030 | f1: 0.985: 100%|██████████| 17/17 [00:07<00:00,  2.28it/s]\n",
      "Epoch:   8. Train.      Loss: 0.052 | f1: 0.993: 100%|██████████| 17/17 [00:08<00:00,  2.08it/s]\n",
      "Epoch:   9. Train.      Loss: 0.025 | f1: 0.993: 100%|██████████| 17/17 [00:08<00:00,  2.10it/s]\n",
      "Epoch:  10. Train.      Loss: 0.034 | f1: 0.993: 100%|██████████| 17/17 [00:08<00:00,  2.08it/s]\n"
     ]
    }
   ],
   "source": [
    "# train the model\n",
    "_ = train_model(\n",
    "    model,\n",
    "    (train_loader, None),\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    num_epochs=10\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T09:33:51.082134Z",
     "start_time": "2024-05-21T09:32:40.576996Z"
    }
   },
   "id": "d4237e22c37245e5"
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [],
   "source": [
    "filepath = f'{ROOT}/models/{model.task}_{model.coin_type}.pt'\n",
    "save_trainable_params(model, filepath)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T09:33:51.425360Z",
     "start_time": "2024-05-21T09:33:51.083357Z"
    }
   },
   "id": "a0345026fe7800f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predicting CHF tails"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c3b7e6bd36ce911c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Datasets and DataLoaders"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "98d507cc53855a04"
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [],
   "source": [
    "# split the image paths into train and validation\n",
    "labels_path = \"../data/classification/chf_tails.json\"\n",
    "images_train, _, labels_train, _ = split_data(\n",
    "    coins_path, 0, \"classification\", labels_path, \"chf-tails\"\n",
    ")\n",
    "\n",
    "# get train and val dataset instances\n",
    "train_ds = ClassificationDataset(\n",
    "    image_paths=images_train,\n",
    "    labels=labels_train,\n",
    "    transform=train_tf,\n",
    ")\n",
    "\n",
    "# create dataloaders\n",
    "train_loader = DataLoader(train_ds, batch_size=8)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T09:34:18.917183Z",
     "start_time": "2024-05-21T09:34:18.873346Z"
    }
   },
   "id": "c57f61814052dda4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Modelling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55dca7fe3b85304c"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "model = CoinClassifier(num_classes=7, coin_type=\"chf-tails\", freeze=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T09:37:39.731727Z",
     "start_time": "2024-05-21T09:37:38.844703Z"
    }
   },
   "id": "d15600e2b43051e0"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.model.parameters(), lr=0.00005, weight_decay=0.2)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T09:37:39.794782Z",
     "start_time": "2024-05-21T09:37:39.731945Z"
    }
   },
   "id": "a2415a8bf4ca3c16"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   1. Train.      Loss: 1.398 | f1: 0.450: 100%|██████████| 5/5 [00:04<00:00,  1.15it/s]\n",
      "Epoch:   2. Train.      Loss: 0.814 | f1: 0.675: 100%|██████████| 5/5 [00:02<00:00,  2.18it/s]\n",
      "Epoch:   3. Train.      Loss: 0.584 | f1: 0.850: 100%|██████████| 5/5 [00:02<00:00,  2.50it/s]\n",
      "Epoch:   4. Train.      Loss: 0.427 | f1: 0.900: 100%|██████████| 5/5 [00:01<00:00,  2.51it/s]\n",
      "Epoch:   5. Train.      Loss: 0.346 | f1: 0.900: 100%|██████████| 5/5 [00:02<00:00,  2.43it/s]\n",
      "Epoch:   6. Train.      Loss: 0.220 | f1: 0.975: 100%|██████████| 5/5 [00:02<00:00,  2.39it/s]\n",
      "Epoch:   7. Train.      Loss: 0.229 | f1: 0.975: 100%|██████████| 5/5 [00:02<00:00,  2.33it/s]\n",
      "Epoch:   8. Train.      Loss: 0.181 | f1: 1.000: 100%|██████████| 5/5 [00:02<00:00,  2.27it/s]\n",
      "Epoch:   9. Train.      Loss: 0.158 | f1: 1.000: 100%|██████████| 5/5 [00:02<00:00,  2.25it/s]\n",
      "Epoch:  10. Train.      Loss: 0.119 | f1: 1.000: 100%|██████████| 5/5 [00:02<00:00,  2.28it/s]\n",
      "Epoch:  11. Train.      Loss: 0.103 | f1: 1.000: 100%|██████████| 5/5 [00:02<00:00,  2.26it/s]\n",
      "Epoch:  12. Train.      Loss: 0.100 | f1: 1.000: 100%|██████████| 5/5 [00:02<00:00,  2.23it/s]\n",
      "Epoch:  13. Train.      Loss: 0.073 | f1: 1.000: 100%|██████████| 5/5 [00:02<00:00,  2.18it/s]\n",
      "Epoch:  14. Train.      Loss: 0.088 | f1: 1.000: 100%|██████████| 5/5 [00:02<00:00,  2.18it/s]\n",
      "Epoch:  15. Train.      Loss: 0.081 | f1: 1.000: 100%|██████████| 5/5 [00:02<00:00,  2.13it/s]\n",
      "Epoch:  16. Train.      Loss: 0.075 | f1: 1.000: 100%|██████████| 5/5 [00:02<00:00,  2.18it/s]\n",
      "Epoch:  17. Train.      Loss: 0.061 | f1: 1.000: 100%|██████████| 5/5 [00:02<00:00,  2.17it/s]\n",
      "Epoch:  18. Train.      Loss: 0.057 | f1: 1.000: 100%|██████████| 5/5 [00:02<00:00,  2.17it/s]\n",
      "Epoch:  19. Train.      Loss: 0.053 | f1: 1.000: 100%|██████████| 5/5 [00:02<00:00,  2.16it/s]\n",
      "Epoch:  20. Train.      Loss: 0.082 | f1: 1.000: 100%|██████████| 5/5 [00:02<00:00,  2.09it/s]\n",
      "Epoch:  21. Train.      Loss: 0.049 | f1: 1.000: 100%|██████████| 5/5 [00:02<00:00,  2.09it/s]\n",
      "Epoch:  22. Train.      Loss: 0.065 | f1: 1.000: 100%|██████████| 5/5 [00:02<00:00,  2.09it/s]\n",
      "Epoch:  23. Train.      Loss: 0.052 | f1: 1.000: 100%|██████████| 5/5 [00:02<00:00,  2.09it/s]\n",
      "Epoch:  24. Train.      Loss: 0.078 | f1: 0.975: 100%|██████████| 5/5 [00:02<00:00,  2.12it/s]\n",
      "Epoch:  25. Train.      Loss: 0.036 | f1: 1.000: 100%|██████████| 5/5 [00:02<00:00,  2.14it/s]\n",
      "Epoch:  26. Train.      Loss: 0.033 | f1: 1.000: 100%|██████████| 5/5 [00:02<00:00,  2.15it/s]\n"
     ]
    }
   ],
   "source": [
    "_ = train_model(\n",
    "    model,\n",
    "    (train_loader, None),\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    num_epochs=26\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T09:38:40.811455Z",
     "start_time": "2024-05-21T09:37:39.797662Z"
    }
   },
   "id": "327a47343073151f"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "filepath = f'{ROOT}/models/{model.task}_{model.coin_type}.pt'\n",
    "save_trainable_params(model, filepath)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T09:39:27.172015Z",
     "start_time": "2024-05-21T09:39:26.934364Z"
    }
   },
   "id": "d407c9f1807b6463"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Predicting CHF heads"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "76b883f2738973a0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Datasets and Dataloaders"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4dee2f8eae67aa6"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "# split the image paths into train and validation\n",
    "labels_path = \"../data/classification/chf_heads.json\"\n",
    "images_train, _, labels_train, _ = split_data(\n",
    "    coins_path, 0, \"classification\", labels_path, \"chf-heads\"\n",
    ")\n",
    "\n",
    "# get train and val dataset instances\n",
    "train_ds = ClassificationDataset(\n",
    "    image_paths=images_train,\n",
    "    labels=labels_train,\n",
    "    transform=train_tf,\n",
    ")\n",
    "\n",
    "# create dataloaders\n",
    "train_loader = DataLoader(train_ds, batch_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T09:39:51.377310Z",
     "start_time": "2024-05-21T09:39:51.334958Z"
    }
   },
   "id": "33c2486b8e151e5e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Modelling"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "edb9b2e2252cf1b1"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "model = CoinClassifier(num_classes=3, coin_type=\"chf-heads\", freeze=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T09:39:53.422429Z",
     "start_time": "2024-05-21T09:39:52.379697Z"
    }
   },
   "id": "3be78501b605eba7"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.model.parameters(), lr=0.00001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=3, eta_min=1e-6)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T09:39:54.065030Z",
     "start_time": "2024-05-21T09:39:54.026998Z"
    }
   },
   "id": "3918a957ccef60f9"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   1. Train.      Loss: 1.025 | f1: 0.535: 100%|██████████| 6/6 [00:02<00:00,  2.05it/s]\n",
      "Epoch:   2. Train.      Loss: 0.804 | f1: 0.674: 100%|██████████| 6/6 [00:02<00:00,  2.98it/s]\n",
      "Epoch:   3. Train.      Loss: 0.694 | f1: 0.757: 100%|██████████| 6/6 [00:02<00:00,  2.99it/s]\n",
      "Epoch:   4. Train.      Loss: 0.547 | f1: 0.854: 100%|██████████| 6/6 [00:02<00:00,  2.90it/s]\n",
      "Epoch:   5. Train.      Loss: 0.502 | f1: 0.917: 100%|██████████| 6/6 [00:02<00:00,  2.96it/s]\n",
      "Epoch:   6. Train.      Loss: 0.421 | f1: 0.917: 100%|██████████| 6/6 [00:02<00:00,  2.86it/s]\n",
      "Epoch:   7. Train.      Loss: 0.351 | f1: 0.938: 100%|██████████| 6/6 [00:02<00:00,  2.84it/s]\n",
      "Epoch:   8. Train.      Loss: 0.334 | f1: 0.938: 100%|██████████| 6/6 [00:02<00:00,  3.00it/s]\n",
      "Epoch:   9. Train.      Loss: 0.273 | f1: 0.979: 100%|██████████| 6/6 [00:02<00:00,  2.97it/s]\n",
      "Epoch:  10. Train.      Loss: 0.187 | f1: 1.000: 100%|██████████| 6/6 [00:01<00:00,  3.02it/s]\n",
      "Epoch:  11. Train.      Loss: 0.163 | f1: 1.000: 100%|██████████| 6/6 [00:01<00:00,  3.01it/s]\n",
      "Epoch:  12. Train.      Loss: 0.155 | f1: 1.000: 100%|██████████| 6/6 [00:02<00:00,  2.85it/s]\n",
      "Epoch:  13. Train.      Loss: 0.136 | f1: 0.979: 100%|██████████| 6/6 [00:02<00:00,  2.71it/s]\n",
      "Epoch:  14. Train.      Loss: 0.122 | f1: 0.979: 100%|██████████| 6/6 [00:02<00:00,  2.59it/s]\n",
      "Epoch:  15. Train.      Loss: 0.078 | f1: 1.000: 100%|██████████| 6/6 [00:02<00:00,  2.38it/s]\n",
      "Epoch:  16. Train.      Loss: 0.083 | f1: 1.000: 100%|██████████| 6/6 [00:02<00:00,  2.26it/s]\n",
      "Epoch:  17. Train.      Loss: 0.064 | f1: 1.000: 100%|██████████| 6/6 [00:02<00:00,  2.20it/s]\n",
      "Epoch:  18. Train.      Loss: 0.064 | f1: 1.000: 100%|██████████| 6/6 [00:02<00:00,  2.26it/s]\n",
      "Epoch:  19. Train.      Loss: 0.052 | f1: 1.000: 100%|██████████| 6/6 [00:02<00:00,  2.15it/s]\n",
      "Epoch:  20. Train.      Loss: 0.046 | f1: 1.000: 100%|██████████| 6/6 [00:02<00:00,  2.19it/s]\n",
      "Epoch:  21. Train.      Loss: 0.039 | f1: 1.000: 100%|██████████| 6/6 [00:02<00:00,  2.18it/s]\n",
      "Epoch:  22. Train.      Loss: 0.031 | f1: 1.000: 100%|██████████| 6/6 [00:02<00:00,  2.02it/s]\n",
      "Epoch:  23. Train.      Loss: 0.030 | f1: 1.000: 100%|██████████| 6/6 [00:02<00:00,  2.12it/s]\n",
      "Epoch:  24. Train.      Loss: 0.035 | f1: 1.000: 100%|██████████| 6/6 [00:02<00:00,  2.09it/s]\n",
      "Epoch:  25. Train.      Loss: 0.023 | f1: 1.000: 100%|██████████| 6/6 [00:03<00:00,  1.89it/s]\n",
      "Epoch:  26. Train.      Loss: 0.027 | f1: 1.000: 100%|██████████| 6/6 [00:02<00:00,  2.07it/s]\n",
      "Epoch:  27. Train.      Loss: 0.024 | f1: 1.000: 100%|██████████| 6/6 [00:02<00:00,  2.09it/s]\n",
      "Epoch:  28. Train.      Loss: 0.018 | f1: 1.000: 100%|██████████| 6/6 [00:02<00:00,  2.11it/s]\n",
      "Epoch:  29. Train.      Loss: 0.045 | f1: 0.979: 100%|██████████| 6/6 [00:03<00:00,  1.88it/s]\n",
      "Epoch:  30. Train.      Loss: 0.017 | f1: 1.000: 100%|██████████| 6/6 [00:03<00:00,  2.00it/s]\n"
     ]
    }
   ],
   "source": [
    "_ = train_model(\n",
    "    model,\n",
    "    (train_loader, None),\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    num_epochs=30\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T09:41:10.050442Z",
     "start_time": "2024-05-21T09:39:54.451448Z"
    }
   },
   "id": "2e15efe6ae363e4b"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "filepath = f'{ROOT}/models/{model.task}_{model.coin_type}.pt'\n",
    "save_trainable_params(model, filepath)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-21T09:41:10.388028Z",
     "start_time": "2024-05-21T09:41:10.049437Z"
    }
   },
   "id": "1e199b7cdcd24683"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "932fa0c5b24cd1b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
