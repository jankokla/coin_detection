{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Inference\n",
    "\n",
    "This notebook is for generating Kaggle submission file. It currently incorporates two neural networks that perform segmentation and then classification."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b403d1831804e261"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Setup"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bdcddaa2d8e23001"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8eae60b35be2138",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T08:45:23.869909Z",
     "start_time": "2024-05-20T08:45:23.853921Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:04:15.109582Z",
     "start_time": "2024-05-20T09:04:15.068474Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from scripts.models import CoinLocalizer, CoinClassifier\n",
    "from scripts.training import get_best_available_device, load_params\n",
    "from scripts.utils import SegmentationDataset, split_data, ClassificationDataset, \\\n",
    "    generate_hough, get_cropped_image, get_segmentation, get_class, get_bb_coordinates, calculate_f1_score\n",
    "from scripts.config import example_row, row_template, ID_TO_LABEL, ID_TO_CCY, ID_TO_EUR, ID_TO_SIDE, ID_TO_CHF_IMG, \\\n",
    "    size_dict\n",
    "\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset\n",
    "\n",
    "Specify the test directory, generate Imagenet specific transforms, initialize the dataset and put it into dataloader."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "608c78b94ab3167a"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9bb68d0734998a6",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T08:45:35.110919Z",
     "start_time": "2024-05-20T08:45:35.073706Z"
    }
   },
   "outputs": [],
   "source": [
    "test_directory = \"../data/test\"\n",
    "test_image_paths, _, _, _ = split_data(test_directory, 0.0, 'inference')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd80a6e05cdd91b3",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T08:45:35.327173Z",
     "start_time": "2024-05-20T08:45:35.289009Z"
    }
   },
   "outputs": [],
   "source": [
    "seg_tf = A.Compose([\n",
    "    A.Resize(width=600, height=400, always_apply=True),\n",
    "    A.PadIfNeeded(min_height=416, min_width=608, always_apply=True),\n",
    "])\n",
    "\n",
    "cls_tf = A.Compose([\n",
    "    A.Resize(width=224, height=224, always_apply=True),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), always_apply=True)  # imagenet specific\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2822f296bd7322c8",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T08:45:35.542594Z",
     "start_time": "2024-05-20T08:45:35.500053Z"
    }
   },
   "outputs": [],
   "source": [
    "test_ds = SegmentationDataset(\n",
    "    image_paths=test_image_paths,\n",
    "    transform=seg_tf,\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(test_ds, batch_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Models\n",
    "\n",
    "Initialize segmentation and classification models and load pre-trained weights."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9ebe5405b921096"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "afff49e81eb3ef9d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:48:53.079717Z",
     "start_time": "2024-05-20T09:48:48.206441Z"
    }
   },
   "outputs": [],
   "source": [
    "# initialize models\n",
    "seg_model = CoinLocalizer()\n",
    "seg_model = load_params(seg_model, 'segmentation_.pt')\n",
    "\n",
    "ccy_model = CoinClassifier(num_classes=2, coin_type=\"ccy\")\n",
    "ccy_model = load_params(ccy_model, 'classification_ccy.pt')\n",
    "\n",
    "eur_model = CoinClassifier(num_classes=8, coin_type=\"eur\", freeze=False)\n",
    "eur_model = load_params(eur_model, 'classification_eur.pt')\n",
    "\n",
    "side_model = CoinClassifier(num_classes=2, coin_type=\"heads-tails\")\n",
    "side_model = load_params(side_model, 'classification_heads-tails.pt')\n",
    "\n",
    "chf_tail_model = CoinClassifier(num_classes=7, coin_type=\"chf-tails\")\n",
    "chf_tail_model = load_params(chf_tail_model, 'classification_chf-tails.pt')\n",
    "\n",
    "chf_head_model = CoinClassifier(num_classes=3, coin_type=\"chf-heads\", freeze=False)\n",
    "chf_head_model = load_params(chf_head_model, 'classification_chf-heads.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "# put them to mps or gpu if possible\n",
    "device = get_best_available_device()\n",
    "\n",
    "ccy_model = ccy_model.to(device)\n",
    "model = seg_model.to(device)\n",
    "eur_model = eur_model.to(device)\n",
    "side_model = side_model.to(device)\n",
    "chf_tail_model = chf_tail_model.to(device)\n",
    "chf_head_model = chf_head_model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:48:54.691101Z",
     "start_time": "2024-05-20T09:48:53.871255Z"
    }
   },
   "id": "9b829261a891d689"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference\n",
    "\n",
    "Iterate over images, extract coins and predict their class."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "41fc51ad328623dc"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "# generate empty df for predictions\n",
    "df = pd.DataFrame(columns=example_row)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:48:54.819019Z",
     "start_time": "2024-05-20T09:48:54.783187Z"
    }
   },
   "id": "de8b71edb130932f"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "# define label mappers\n",
    "id_to_label = np.vectorize(lambda x: ID_TO_LABEL.get(x, \"unknown\"))\n",
    "id_to_ccy = np.vectorize(lambda x: ID_TO_CCY.get(x, \"unknown\"))\n",
    "id_to_eur = np.vectorize(lambda x: ID_TO_EUR.get(x, \"unknown\"))\n",
    "id_to_side = np.vectorize(lambda x: ID_TO_SIDE.get(x, \"unknown\"))\n",
    "id_to_chf_img = np.vectorize(lambda x: ID_TO_CHF_IMG.get(x, \"unknown\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:48:55.155651Z",
     "start_time": "2024-05-20T09:48:55.114737Z"
    }
   },
   "id": "21894080026655a"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def make_final_decision(text_labels, probabilities, radii) -> list:\n",
    "    \n",
    "    chf_idx = [i for i, text_label in enumerate(text_labels) if text_label in ['2CHF/1CHF/0.5CHF','0.2CHF/0.1CHF/0.05CHF']]\n",
    "    ood_idx = [i for i, text_label in enumerate(text_labels) if text_label in [\"OOD\"]]\n",
    "    \n",
    "    remaining_prob_with_idx = [(i, p) for i, p in enumerate(probabilities) if (i not in chf_idx and i not in ood_idx)]\n",
    "    remaining_prob_values = [p for i, p in remaining_prob_with_idx]\n",
    "\n",
    "    if remaining_prob_values:\n",
    "        # get the index of the highest probability\n",
    "        max_prob_idx = np.argmax(remaining_prob_values)\n",
    "        \n",
    "        # get the original index of the highest probability\n",
    "        max_prob_original_idx = remaining_prob_with_idx[max_prob_idx][0]\n",
    "    \n",
    "        for index in chf_idx:\n",
    "            coin_radii = radii[index]\n",
    "            refer_coin_radii = radii[max_prob_original_idx]\n",
    "            refer_coin_label = text_labels[max_prob_original_idx]\n",
    "            real_ratio = refer_coin_radii / coin_radii\n",
    "            \n",
    "            if text_labels[index] =='2CHF/1CHF/0.5CHF':\n",
    "                \n",
    "                refer_ratio_2chf = size_dict[refer_coin_label] / size_dict['2CHF']\n",
    "                refer_ratio_1chf = size_dict[refer_coin_label] / size_dict['1CHF']\n",
    "                refer_ratio_05chf = size_dict[refer_coin_label] / size_dict['0.5CHF']\n",
    "                \n",
    "                current_labels = ['2CHF', '1CHF', '0.5CHF']\n",
    "                ratios = [refer_ratio_2chf, refer_ratio_1chf, refer_ratio_05chf]\n",
    "                closest_index = min(enumerate(ratios), key=lambda x: abs(x[1] - real_ratio))[0]\n",
    "                \n",
    "                text_labels[index] = current_labels[closest_index]\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                refer_ratio_02chf = size_dict[refer_coin_label] / size_dict['0.2CHF']\n",
    "                refer_ratio_01chf = size_dict[refer_coin_label] / size_dict['0.1CHF']\n",
    "                refer_ratio_005chf = size_dict[refer_coin_label] / size_dict['0.05CHF']\n",
    "                \n",
    "                current_labels = ['0.2CHF', '0.1CHF', '0.05CHF']\n",
    "                ratios = [refer_ratio_02chf, refer_ratio_01chf, refer_ratio_005chf]\n",
    "                closest_index = min(enumerate(ratios), key=lambda x: abs(x[1] - real_ratio))[0]\n",
    "                \n",
    "                text_labels[index] = current_labels[closest_index]\n",
    "    else: \n",
    "        for index in chf_idx:\n",
    "            if text_labels[index] =='2CHF/1CHF/0.5CHF':\n",
    "                text_labels[index] = random.choice(['2CHF', '1CHF', '0.5CHF'])\n",
    "            else: \n",
    "                text_labels[index] = random.choice(['0.2CHF', '0.1CHF', '0.05CHF'])\n",
    "            \n",
    "    return text_labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:54:58.570692Z",
     "start_time": "2024-05-20T09:54:58.531596Z"
    }
   },
   "id": "42c0d077c3b5a49d"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4af771d8de768670",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T10:00:29.388102Z",
     "start_time": "2024-05-20T09:55:07.373536Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing images: 100%|██████████| 162/162 [05:21<00:00,  1.99s/it]\n"
     ]
    }
   ],
   "source": [
    "for i, (image, _, filename) in enumerate(tqdm(test_loader, desc='Analyzing images')):\n",
    "\n",
    "    image = image.to(device)\n",
    "\n",
    "    predicted = get_segmentation(model, image)\n",
    "\n",
    "    circles, hough_img = generate_hough(predicted, image)\n",
    "    \n",
    "    original_img = Image.open(f\"../data/test/{filename[0]}\")\n",
    "    original_img = np.array(original_img)\n",
    "    \n",
    "    # segmentation was done on smaller images -> reset the coordinates for original images\n",
    "    x_ratio = 6000 / image.shape[3]\n",
    "    y_ratio = 4000 / image.shape[2]\n",
    "\n",
    "    labels = []\n",
    "    probabilities = []\n",
    "    boxes = []\n",
    "    radii = [r for x, y, r in circles]\n",
    "\n",
    "    for j, (x, y, r) in enumerate(circles):\n",
    "        \n",
    "        cropped_image = get_cropped_image(original_img, x, y, r, x_ratio, y_ratio)\n",
    "        \n",
    "        box = list(get_bb_coordinates(x, y, r, x_ratio, y_ratio))\n",
    "        boxes.append(box)\n",
    "        \n",
    "        # initiate the dataloader\n",
    "        coin_loader = DataLoader(ClassificationDataset(cropped_image, transform=cls_tf))\n",
    "        coin_iterator = iter(coin_loader)\n",
    "        coin, _, radius = next(coin_iterator)\n",
    "        \n",
    "        coin = coin.to(device)\n",
    "        \n",
    "        # predict currency\n",
    "        ccy_id, ccy_label, ccy_prob = get_class(ccy_model, coin, id_to_ccy)\n",
    "        \n",
    "        # if not sure about the currency -> OOD\n",
    "        if ccy_prob < 0.9:  \n",
    "            labels.append(\"OOD\")\n",
    "            probabilities.append(ccy_prob)\n",
    "        \n",
    "        # if EUR -> predict EUR coin type\n",
    "        elif ccy_id == 1:\n",
    "            \n",
    "            eur_id, eur_label, eur_prob = get_class(eur_model, coin, id_to_eur)\n",
    "            \n",
    "            if eur_prob < 0.5:\n",
    "                labels.append(\"OOD\")\n",
    "            else:\n",
    "                labels.append(f\"{eur_label}\")\n",
    "            \n",
    "            probabilities.append(eur_prob)\n",
    "                \n",
    "        # if CHF -> predict CHF head or tails\n",
    "        else:\n",
    "            \n",
    "            side_id, side_label, side_prob = get_class(side_model, coin, id_to_side)\n",
    "\n",
    "            # if tail -> predict CHF coin type\n",
    "            if side_id == 0:\n",
    "                chf_tail_id, chf_tail_label, chf_tail_prob = get_class(\n",
    "                    chf_tail_model, coin, id_to_label\n",
    "                )\n",
    "                labels.append(f\"{chf_tail_label}\")\n",
    "                probabilities.append(chf_tail_prob)\n",
    "            \n",
    "            # if head -> predict picture type (3 options)\n",
    "            else:\n",
    "                chf_head_id, chf_head_label, chf_head_prob = get_class(\n",
    "                    chf_head_model, coin, id_to_chf_img\n",
    "                )\n",
    "                \n",
    "                # since 5CHF has distinctive picture\n",
    "                if chf_head_id == 0:\n",
    "                    labels.append(\"5CHF\")\n",
    "                \n",
    "                # TODO: need to have dynamic radius dependent decision-making\n",
    "                else:\n",
    "                    labels.append(f\"{chf_head_label}\") \n",
    "                    \n",
    "                probabilities.append(chf_head_prob)\n",
    "                    \n",
    "    labels = make_final_decision(labels, probabilities, radii)\n",
    "    \n",
    "    prob_img = draw_bounding_boxes(\n",
    "        image=torch.tensor(original_img, dtype=torch.uint8).permute(2, 0, 1), \n",
    "        boxes=torch.tensor(boxes, dtype=torch.int16), \n",
    "        labels=labels, \n",
    "        colors=\"#FF0000\",\n",
    "        font=\"Arial\",\n",
    "        width=16,\n",
    "        font_size=110\n",
    "    )\n",
    "    \n",
    "    row = row_template.copy()\n",
    "    counts = dict(Counter(labels))\n",
    "    row.update(counts)\n",
    "    df.loc[filename[0].split('.')[0]] = row\n",
    "    \n",
    "    im = Image.fromarray(prob_img.cpu().numpy().transpose(1, 2, 0))\n",
    "    im.save(f\"../inference/{filename[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "          5CHF  2CHF  1CHF  0.5CHF  0.2CHF  0.1CHF  0.05CHF  2EUR  1EUR  \\\nid                                                                        \nL0000000     0     0     1       0       1       0        0     1     0   \nL0000001     1     1     1       0       2       0        1     0     2   \nL0000002     1     1     0       1       0       0        0     0     0   \nL0000003     0     2     0       0       0       1        1     1     0   \nL0000004     0     0     1       1       1       1        0     0     1   \n\n          0.5EUR  0.2EUR  0.1EUR  0.05EUR  0.02EUR  0.01EUR  OOD  \nid                                                                \nL0000000       0       0       0        0        0        0    0  \nL0000001       1       0       0        1        0        0    0  \nL0000002       0       0       0        0        0        0    1  \nL0000003       0       1       0        0        1        0    1  \nL0000004       0       0       0        0        1        0    0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>5CHF</th>\n      <th>2CHF</th>\n      <th>1CHF</th>\n      <th>0.5CHF</th>\n      <th>0.2CHF</th>\n      <th>0.1CHF</th>\n      <th>0.05CHF</th>\n      <th>2EUR</th>\n      <th>1EUR</th>\n      <th>0.5EUR</th>\n      <th>0.2EUR</th>\n      <th>0.1EUR</th>\n      <th>0.05EUR</th>\n      <th>0.02EUR</th>\n      <th>0.01EUR</th>\n      <th>OOD</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>L0000000</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>L0000001</th>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>L0000002</th>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>L0000003</th>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>L0000004</th>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add index name as necessary for Kaggle\n",
    "df.index.name='id'\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:36:24.986065Z",
     "start_time": "2024-05-20T09:36:24.924247Z"
    }
   },
   "id": "19baabd1526376c8"
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [],
   "source": [
    "df.to_csv('test_submission.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T09:36:26.312972Z",
     "start_time": "2024-05-20T09:36:26.264906Z"
    }
   },
   "id": "9472a87fb947681a"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7680065818954708"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_f1_score('sample_submission_completed.csv', 'test_submission.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-20T13:17:24.706571Z",
     "start_time": "2024-05-20T13:17:24.684047Z"
    }
   },
   "id": "5447a600ed8fdf17"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "56f6e8b9bd85fe85"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
