{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Segmentation\n",
    "\n",
    "One of the approaches that we aimed to try was to use segmentation to detect coins from images and based on the predicted binary mask, we can localize them and use this as input to feature extraction and classification. We will experiment with classic **Unet encoder** with pretrained **ResNet backbone** (decoder)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "397655b8458c38cc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d9902570e863ba0d"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T06:28:11.153265Z",
     "start_time": "2024-05-06T06:28:11.111510Z"
    }
   },
   "id": "a31e34bbb14feb2"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-06T06:28:19.048824Z",
     "start_time": "2024-05-06T06:28:11.132363Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.encoders import get_preprocessing_fn\n",
    "from scripts.viz import plot_images\n",
    "from scripts.training import train_model\n",
    "from scripts.utils import SegmentationDataset, split_data, get_prediction\n",
    "import albumentations as A\n",
    "from torch.utils.data import random_split, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameters and Config"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "96f2763e18d70013"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "# let's specify paths to training images and masks\n",
    "seg_directory = \"data/train\"  # TODO: update"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T06:28:19.087368Z",
     "start_time": "2024-05-06T06:28:19.050370Z"
    }
   },
   "id": "482af80288f4ff8e"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# training hyperparameters\n",
    "num_epochs = 10\n",
    "batch_size = 4\n",
    "lr = 0.005"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T06:28:19.133562Z",
     "start_time": "2024-05-06T06:28:19.088787Z"
    }
   },
   "id": "162acd40428ef0df"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Augmentation\n",
    "\n",
    "We first define data augmentations for more robust model, then generate datasets and dataloaders for training and validation."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "abeab7013d2e70cf"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "# define data augmentation for train and validation\n",
    "train_tf = A.Compose([\n",
    "    A.Resize(width=600, height=400, always_apply=True),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.4),\n",
    "    A.RandomGamma(gamma_limit=(80, 120), p=0.4),\n",
    "    A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.4)\n",
    "])\n",
    "\n",
    "valid_tf = A.Compose([A.Resize(height=600, width=400, always_apply=True)])\n",
    "\n",
    "# get bacbbone specific transformations\n",
    "preprocess_input = get_preprocessing_fn('resnet50', pretrained='imagenet')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T06:28:19.192201Z",
     "start_time": "2024-05-06T06:28:19.135943Z"
    }
   },
   "id": "df9d3276380a5ede"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# split the image paths into train and validation\n",
    "image_path_train, image_path_val, mask_path_train, mask_path_val \\\n",
    "    = split_data(seg_directory, 0.2)\n",
    "\n",
    "# get train and val dataset instances\n",
    "train_ds = SegmentationDataset(\n",
    "    image_paths=image_path_train,\n",
    "    mask_paths=mask_path_train,\n",
    "    transform=train_tf,\n",
    "    preprocess=preprocess_input\n",
    ")\n",
    "\n",
    "val_ds = SegmentationDataset(\n",
    "    image_paths=image_path_val,\n",
    "    mask_paths=mask_path_val,\n",
    "    transform=valid_tf,\n",
    "    preprocess=preprocess_input\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T06:28:26.740959Z",
     "start_time": "2024-05-06T06:28:26.677251Z"
    }
   },
   "id": "b3f1e6eee882d4aa"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# create dataloaders\n",
    "train_loader = DataLoader(train_ds, batch_size)\n",
    "val_loader = DataLoader(val_ds, batch_size)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7e021d73e1a89974"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Modelling\n",
    "\n",
    "We use `Segmentation Models Pytorch` for model generation, then we define training arguments and train the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "eec27faf679b87e0"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet50\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=3,\n",
    "    classes=1,\n",
    ")\n",
    "\n",
    "# freeze encoder weights\n",
    "model.encoder.training = False"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9be69d7f2152f2c3"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "trainable_params = [param for param in model.parameters() if param.requires_grad == True]\n",
    "optimizer = torch.optim.Adam(trainable_params, lr=lr)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "    optimizer,\n",
    "    T_max=(len(train_loader.dataset) * num_epochs) // train_loader.batch_size,\n",
    ")\n",
    "\n",
    "criterion = smp.losses.DiceLoss(smp.losses.BINARY_MODE, from_logits=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-06T06:28:31.233226Z",
     "start_time": "2024-05-06T06:28:29.490302Z"
    }
   },
   "id": "3924c5ec9264dbcc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# train the model\n",
    "train_losses, valid_losses, train_f1s, valid_f1s = train_model(\n",
    "    model,\n",
    "    (train_loader, val_loader),\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    num_epochs\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "974b5b85673d145e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Inference\n",
    "\n",
    "Let's see how well the model does"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6499b2f3cdb274f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for image, label in val_loader:\n",
    "\n",
    "    predicted = get_prediction(model, image)\n",
    "\n",
    "    plot_images(\n",
    "        axis=False,\n",
    "        original=image,\n",
    "        ground_truth=label,\n",
    "        predicted=predicted\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d698e0edba16a7e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
